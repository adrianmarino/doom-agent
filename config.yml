env:
  config_file: ./scenarios/defend_the_center.cfg
  variables:
    - kills
    - ammo
    - health
  train:
    show: False
    sound: False
    advance_steps: 4 # Number of frames to advance environment after apply an action to this.
  play:
    show: True
    sound: True
    advance_steps: 1 # Number of frames to advance environment after apply an action to this.
    episodes: 3
    frame_delay: 0.125

hiperparams:
  input_shape: (64, 64, 4) # Main model input shape (4 images in gray scale) (width, heights, channels).
  chop_bottom_height: 0 # pixels chapped from bottom of input frame. Used minimize input size.
  lr: 0.0001 # Main model learning rate.
  gamma: 0.99 # Discount factor of TD target calculus.
  batch_size: 32 # Model fit batch size.
  train_freq: 100 # Number of time steps between training interval.
  update_target_model_freq: 3000 # Number of time steps between  TD Target model weights update.
  memory_size: 50000 # Number of previous transitions to remember.
  epsilon:
    initial: 1.0
    final: 0.001
  phase_time:
    observe: 2000 # Number of times that epsilon-greedy method select a random action.
    explore: 50000 # Number of times that epsilon-greedy method select a predicted action(from a neural network).
  rewards:
    kills: 1,  # Increase X rewards every time an enemy is killed.
    ammo: -1,  # Decrease X rewards every time a bullet is used.
    health: -1 # Decrease X rewards every time health level goes down.

checkpoint:
  freq: 5000 # Save model weights every X times.
  path: checkpoints # Path were weights files are saved.

metric:
  path: ./metrics # Tensor board metrics path.

logger:
  name: agent
  path: logs
  level: INFO
  message_format: "%(levelname)s %(asctime)s - %(message)s"
  date_format: "%Y-%m-%d %H:%M:%S"
