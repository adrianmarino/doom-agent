env:
  config_file: ./scenarios/defend_the_center.cfg
  variables:
    - kills
    - ammo
    - health
  train:
    show: False
    sound: False
    advance_steps: 4 # Number of frames to advance environment after apply an stategy to this.
  play:
    show: True
    sound: False
    advance_steps: 4 # Number of frames to advance environment after apply an stategy to this.
    episodes: 20
    frame_delay: 0.05

hiperparams:
  input_shape: (64, 64, 4) # Main model input shape (4 images in gray scale) (width, heights, channels).
  chop_bottom_height: 0 # pixels chapped from bottom of input frame. Used minimize input size.
  lr: 0.0001 # Main model learning rate.
  gamma: 0.99 # Discount factor of TD target calculus.
  batch_size: 16 # Model fit batch size.
  train_freq: 100 # Number of time steps between training interval.
  update_target_model_freq: 2000 # Number of time steps between  TD Target model weights update.
  memory_size: 50000 # Number of previous transitions to remember.
  epsilon:
    initial: 1.0
    final: 0.001
  phase_time:
    observe: 2000 # Number of times that epsilon-greedy method select a random stategy.
    explore: 50000 # Number of times that epsilon-greedy method select a predicted stategy(from a neural network).
    train: 5000
  rewards:
    kills: 1.5  # Increase X reward every time an enemy is killed.
    ammo: -1.2  # Decrease X reward every time a bullet is used.
    health: -1.5 # Decrease X reward every time health level goes down.

checkpoint:
  freq: 5000 # Save model weights every X times.
  path: checkpoints # Path were weights files are saved.

metric:
  path: ./metrics # Tensor board metrics path.

report:
  path: ./reports
  last_times: 0

logger:
  name: agent
  path: logs
  level: INFO
  message_format: "%(levelname)s %(asctime)s - %(message)s"
  date_format: "%Y-%m-%d %H:%M:%S"
